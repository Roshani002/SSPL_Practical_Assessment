{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38802865",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04cf802",
   "metadata": {},
   "source": [
    "## Encoding pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f842c3",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f8c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1161e9",
   "metadata": {},
   "source": [
    "### Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb78aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"processed_data/cleaned_data.pkl\")\n",
    "print(\"Cleaned data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822176af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4931 entries, 0 to 4999\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            4931 non-null   object \n",
      " 1   SeniorCitizen     4931 non-null   int64  \n",
      " 2   Partner           4931 non-null   object \n",
      " 3   Dependents        4931 non-null   object \n",
      " 4   tenure            4931 non-null   int64  \n",
      " 5   PhoneService      4931 non-null   object \n",
      " 6   MultipleLines     4931 non-null   object \n",
      " 7   InternetService   4931 non-null   object \n",
      " 8   OnlineSecurity    4931 non-null   object \n",
      " 9   OnlineBackup      4931 non-null   object \n",
      " 10  DeviceProtection  4931 non-null   object \n",
      " 11  TechSupport       4931 non-null   object \n",
      " 12  StreamingTV       4931 non-null   object \n",
      " 13  StreamingMovies   4931 non-null   object \n",
      " 14  Contract          4931 non-null   object \n",
      " 15  PaperlessBilling  4931 non-null   object \n",
      " 16  PaymentMethod     4931 non-null   object \n",
      " 17  MonthlyCharges    4931 non-null   float64\n",
      " 18  Churn             4931 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(15)\n",
      "memory usage: 770.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6be37",
   "metadata": {},
   "source": [
    "### Custom transformer for multi-column LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445d34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for multi-column LabelEncoder\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.encoders_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                le = LabelEncoder()\n",
    "                # Fit on the specific column\n",
    "                le.fit(X[col].values)\n",
    "                self.encoders_[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                X_copy[col] = self.encoders_[col].transform(X_copy[col].values)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84698692",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69015f96",
   "metadata": {},
   "source": [
    "#### Encoding pipeline general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff9d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column transformers for different encoding types\n",
    "one_hot_cols = ['InternetService', 'PaymentMethod']  \n",
    "ordinal_cols = ['Contract']\n",
    "label_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']  \n",
    "internet_service_label_cols = ['MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "# Create transformers\n",
    "one_hot_transformer = OneHotEncoder(drop=None, sparse_output=False)\n",
    "ordinal_transformer = OrdinalEncoder(categories=[['Month-to-month', 'One year', 'Two year']])\n",
    "\n",
    "# Combine transformers into ColumnTransformer\n",
    "# Use custom transformer for label_cols and internet_service_label_cols\n",
    "encoder_preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', one_hot_transformer, one_hot_cols),\n",
    "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
    "        ('label', MultiColumnLabelEncoder(columns=label_cols), label_cols),\n",
    "        ('internet_label', MultiColumnLabelEncoder(columns=internet_service_label_cols), internet_service_label_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns as they are\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline_tree = Pipeline(steps=[\n",
    "    ('encoder_preprocessor', encoder_preprocessor_tree)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f74745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of data for tree models: (4931, 24)\n",
      "\n",
      " Data for tree-based models saved to encoded_data_tree.pkl\n"
     ]
    }
   ],
   "source": [
    "# Fit the tree-based pipeline\n",
    "df_encoded_tree_data = pipeline_tree.fit_transform(df)\n",
    "\n",
    "# Manually construct feature names for the tree pipeline\n",
    "feature_names_tree = []\n",
    "onehot_names = pipeline_tree.named_steps['encoder_preprocessor'].named_transformers_['onehot'].get_feature_names_out(one_hot_cols)\n",
    "feature_names_tree.extend(onehot_names)\n",
    "feature_names_tree.extend(ordinal_cols)\n",
    "feature_names_tree.extend(label_cols)\n",
    "feature_names_tree.extend(internet_service_label_cols)\n",
    "remainder_features = [col for col in df.columns if col not in (one_hot_cols + ordinal_cols + label_cols + internet_service_label_cols)]\n",
    "feature_names_tree.extend(remainder_features)\n",
    "\n",
    "# Create a DataFrame and save it\n",
    "df_encoded_tree = pd.DataFrame(df_encoded_tree_data, columns=feature_names_tree)\n",
    "print(\"\\nShape of data for tree models:\", df_encoded_tree.shape)\n",
    "df_encoded_tree.head()\n",
    "\n",
    "# Save data for tree-based models\n",
    "df_encoded_tree.to_pickle(\"processed_data/encoded_data_tree.pkl\")\n",
    "print(\"\\n Data for tree-based models saved to encoded_data_tree.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32d3d4",
   "metadata": {},
   "source": [
    "#### Encoding Pipeline for Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f9e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of data for linear models: (4931, 43)\n",
      "\n",
      "Data for linear models saved to encoded_data_linear.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define columns for one-hot and ordinal encoding\n",
    "one_hot_cols_linear = [\n",
    "    'gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling',\n",
    "    'InternetService', 'PaymentMethod', 'MultipleLines', 'OnlineSecurity',\n",
    "    'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "]\n",
    "ordinal_cols = ['Contract'] \n",
    "\n",
    "# Create transformers\n",
    "# Use handle_unknown='ignore' to prevent errors during prediction\n",
    "one_hot_transformer_linear = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ordinal_transformer = OrdinalEncoder(categories=[['Month-to-month', 'One year', 'Two year']])\n",
    "\n",
    "# Create the preprocessor for the linear pipeline\n",
    "encoder_preprocessor_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', one_hot_transformer_linear, one_hot_cols_linear),\n",
    "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the pipeline for linear models\n",
    "pipeline_linear = Pipeline(steps=[\n",
    "    ('encoder_preprocessor', encoder_preprocessor_linear)\n",
    "])\n",
    "\n",
    "# Fit the linear pipeline\n",
    "df_encoded_linear_data = pipeline_linear.fit_transform(df)\n",
    "\n",
    "# Get feature names automatically from the linear pipeline\n",
    "feature_names_linear = pipeline_linear.named_steps['encoder_preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame and save it\n",
    "df_encoded_linear = pd.DataFrame(df_encoded_linear_data, columns=feature_names_linear)\n",
    "print(\"\\nShape of data for linear models:\", df_encoded_linear.shape)\n",
    "df_encoded_linear.head()\n",
    "\n",
    "# Save data for linear models\n",
    "df_encoded_linear.to_pickle(\"processed_data/encoded_data_linear.pkl\")\n",
    "print(\"\\nData for linear models saved to encoded_data_linear.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f4d5f",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e01a3",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c469518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data splits for LINEAR REGRESSION saved.\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target for Regression from the LINEAR-ENCODED data\n",
    "X_reg = df_encoded_linear.drop('remainder__MonthlyCharges', axis=1)\n",
    "y_reg = df_encoded_linear['remainder__MonthlyCharges']\n",
    "\n",
    "# train, test, split for regression\n",
    "X_train_reg_linear, X_test_reg_linear, y_train_reg_linear, y_test_reg_linear = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Save linear regression splits\n",
    "with open(\"processed_data/X_train_reg_linear.pkl\", \"wb\") as f: pickle.dump(X_train_reg_linear, f)\n",
    "with open(\"processed_data/X_test_reg_linear.pkl\", \"wb\") as f: pickle.dump(X_test_reg_linear, f)\n",
    "with open(\"processed_data/y_train_reg_linear.pkl\", \"wb\") as f: pickle.dump(y_train_reg_linear, f)\n",
    "with open(\"processed_data/y_test_reg_linear.pkl\", \"wb\") as f: pickle.dump(y_test_reg_linear, f)\n",
    "\n",
    "print(\" Data splits for LINEAR REGRESSION saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db865f",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a68b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits for CLASSIFICATION saved.\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target for classification from the TREE-ENCODED data\n",
    "X_cls = df_encoded_tree.drop('Churn', axis=1)\n",
    "y_cls = df_encoded_tree['Churn']\n",
    "\n",
    "# train, test, split for classification\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
    ")\n",
    "\n",
    "# Save classification splits\n",
    "with open(\"processed_data/X_train_clf.pkl\", \"wb\") as f: pickle.dump(X_train_cls, f)\n",
    "with open(\"processed_data/X_test_clf.pkl\", \"wb\") as f: pickle.dump(X_test_cls, f)\n",
    "with open(\"processed_data/y_train_clf.pkl\", \"wb\") as f: pickle.dump(y_train_cls, f)\n",
    "with open(\"processed_data/y_test_clf.pkl\", \"wb\") as f: pickle.dump(y_test_cls, f)\n",
    "    \n",
    "print(\"Data splits for CLASSIFICATION saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a7581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
